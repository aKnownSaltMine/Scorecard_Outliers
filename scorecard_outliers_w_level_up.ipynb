{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import native dependencies\n",
    "import os\n",
    "import warnings\n",
    "from datetime import date, datetime\n",
    "from pathlib import Path\n",
    "from shutil import copy, move\n",
    "from time import sleep\n",
    "from Dependencies.setup import setup\n",
    "from Dependencies import gvp_functions as gvp\n",
    "\n",
    "# import dependencies\n",
    "try:\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import pyodbc\n",
    "    import win32com.client\n",
    "    from dateutil.relativedelta import relativedelta\n",
    "    from selenium import webdriver\n",
    "    from selenium.webdriver.chrome.service import Service\n",
    "    from selenium.webdriver.common.action_chains import ActionChains\n",
    "    from selenium.webdriver.common.by import By\n",
    "    from selenium.webdriver.support.select import Select\n",
    "    from selenium.webdriver.support.wait import WebDriverWait\n",
    "    from webdriver_manager.chrome import ChromeDriverManager\n",
    "except ImportError:\n",
    "    setup()\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import pyodbc\n",
    "    import win32com.client\n",
    "    from dateutil.relativedelta import relativedelta\n",
    "    from selenium import webdriver\n",
    "    from selenium.webdriver.chrome.service import Service\n",
    "    from selenium.webdriver.common.action_chains import ActionChains\n",
    "    from selenium.webdriver.common.by import By\n",
    "    from selenium.webdriver.support.select import Select\n",
    "    from selenium.webdriver.support.wait import WebDriverWait\n",
    "    from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "\n",
    "warnings.simplefilter(action='ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# declares helper functions\n",
    "\n",
    "\n",
    "def round_half_up(n, decimals=0):\n",
    "    import math\n",
    "    multiplier = 10 ** decimals\n",
    "    return math.floor(n*multiplier + 0.5) / multiplier\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating fiscal months and lookback periods\n",
    "today = date.today()\n",
    "yesterday = today + relativedelta(days=-1)\n",
    "current_fm = gvp.decide_fm(yesterday)\n",
    "\n",
    "shrink_date = yesterday + relativedelta(days=-30)\n",
    "shrink_fm = gvp.decide_fm(shrink_date)\n",
    "# shrink_fm = gvp.decide_fm(date(2023,1,1))\n",
    "\n",
    "\n",
    "months_to_pull = relativedelta(current_fm, shrink_fm).months + 1\n",
    "\n",
    "months_to_display = 9\n",
    "lookback_month = current_fm - relativedelta(months=months_to_display)\n",
    "print(f'Running for {current_fm.strftime(\"%B %Y\")}')\n",
    "print(f'Lookback period through {lookback_month.strftime(\"%B %Y\")}')\n",
    "\n",
    "# declare path and file names\n",
    "mstr_url = \"\" # Microstrategy URL\n",
    "saves_as = \"Scorecard_Metrics.xlsx\"\n",
    "\n",
    "# cwd = os.path.dirname(__file__)\n",
    "cwd = os.getcwd()\n",
    "data_folder = os.path.join(cwd, 'Data')\n",
    "queries_folder = os.path.join(cwd, 'Queries')\n",
    "shrink_query_file = 'Shrink_Query.sql'\n",
    "roster_query_file = 'VR_Roster_Query.sql'\n",
    "shrink_query_path = os.path.join(queries_folder, shrink_query_file)\n",
    "roster_query_path = os.path.join(queries_folder, roster_query_file)\n",
    "\n",
    "threshold_file = 'Thresholds.xlsx'\n",
    "threshold_path = os.path.join(data_folder, threshold_file)\n",
    "old_scorecard_file = 'Old_Scorecard_Numbers.xlsx'\n",
    "old_scorecard_path = os.path.join(data_folder, old_scorecard_file)\n",
    "new_scorecard_file = 'New_Scorecard_Numbers.xlsx'\n",
    "new_scorecard_path = os.path.join(data_folder, new_scorecard_file)\n",
    "scorecard_file = 'Scorecard_Metrics.xlsx'\n",
    "scorecard_data = os.path.join(data_folder, scorecard_file)\n",
    "\n",
    "template_folder = os.path.join(cwd, 'Templates')\n",
    "template_file = 'Scorecard_Outlier_Template.xlsx'\n",
    "template_path = os.path.join(template_folder, template_file)\n",
    "\n",
    "save_folder = os.path.join(cwd, 'Reports')\n",
    "save_file = f'Scorecard Outliers - {yesterday.strftime(\"%m%d%y\")}.xlsx'\n",
    "save_path = os.path.join(save_folder, save_file)\n",
    "server_folder = r'' # Network Share drive\n",
    "server_path = os.path.join(server_folder, save_file)\n",
    "\n",
    "# declaring paths to local assets\n",
    "src_folder = os.path.join(cwd, 'src')\n",
    "logo = os.path.join(src_folder, 'logo.png')\n",
    "vid_repair = os.path.join(src_folder, 'Leader_Logo.png')\n",
    "\n",
    "downloads_path = os.path.join(Path.home(), 'Downloads')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulling the Data\n",
    "# declare driver\n",
    "print('Downloading Drivers')\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "print('Drivers downloaded')\n",
    "print('--------------------')\n",
    "\n",
    "gvp.download_reports(driver, mstr_url, saves_as, prompt='fm', fiscal_month=current_fm, months=months_to_pull)\n",
    "\n",
    "# # retrieving data from MSTR\n",
    "# # removing old call data if in downloads\n",
    "download_file = os.path.join(downloads_path, saves_as)\n",
    "\n",
    "# # closing chrome driver\n",
    "driver.quit()\n",
    "print(f'{saves_as} Report Downloaded. Moving...')\n",
    "\n",
    "# declaring save path from dataframe and renaming downloaded file to that path\n",
    "file_save_location = os.path.join(data_folder, saves_as)\n",
    "move(download_file, file_save_location)\n",
    "print(f'Saved: {file_save_location}')\n",
    "print('--------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrink_query = f'''\n",
    "Select StdDate AS [Date]\n",
    "\t  ,EmpID\n",
    "\t  ,[Unplanned OOO]\n",
    "\t  ,[Scheduled]\n",
    "FROM (SELECT shr.StdDate\n",
    "\t\t  ,[EmpID]\n",
    "\t\t  ,[ShrinkCategory]\n",
    "\t\t  ,Sum([ShrinkSeconds]) as [Shrink (sec)]\n",
    "\t  FROM [Aspect].[WFM].[BI_Daily_CS_Shrinkage] as shr\n",
    "\t  INNER JOIN [UXID].[EMP].[Workers] AS ros with(NOLOCK)\n",
    "\t  ON REPLACE(shr.[EmpID],' ','') = REPLACE(ros.[NETIQWORKERID], ' ', '')\n",
    "\t  INNER JOIN [UXID].[REF].[Departments] AS dept WITH(NOLOCK)\n",
    "\t  ON ros.DEPARTMENTID = dept.DEPARTMENTID\n",
    "\t  WHERE (dept.NAME LIKE '%Video%')\n",
    "\t  AND (shr.StdDate BETWEEN '{gvp.decide_fm_beginning(shrink_fm - relativedelta(months=2)).strftime(\"%m/%d/%Y\")}' AND '{gvp.decide_fm_end(current_fm).strftime(\"%m/%d/%Y\")}') \n",
    "\t  AND (shr.ShrinkCategory IN ('Scheduled', 'Unplanned OOO'))\n",
    "\t  AND ([ShrinkCode] <> 'STF-MGMT-OVR UNPAID')\n",
    "\t  GROUP BY shr.StdDate, shr.EmpID, shr.ShrinkCategory) as Shrink_Table\n",
    "PIVOT(\n",
    "\tSUM([Shrink (sec)])\n",
    "\tFOR [ShrinkCategory] IN ([Unplanned OOO], [Scheduled])\n",
    "\t) AS piv\n",
    "ORDER BY [StdDate] DESC, EmpID ASC;\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_query = f'''\n",
    "Select StdDate AS [Date]\n",
    "\t  ,EmpID\n",
    "\t  ,[Out of Center - Planned]\n",
    "\t  ,[Out of Center - Unplanned]\n",
    "\t  ,[Scheduled Hours]\n",
    "FROM (SELECT shr.StdDate\n",
    "\t\t  ,[EmpID]\n",
    "\t\t  ,[ShrinkType]\n",
    "\t\t  ,Sum([ShrinkSeconds]) as [Shrink (sec)]\n",
    "\t  FROM [Aspect].[WFM].[BI_Daily_CS_Shrinkage] as shr\n",
    "\t  INNER JOIN [UXID].[EMP].[Workers] AS ros with(NOLOCK)\n",
    "\t  ON REPLACE(shr.[EmpID],' ','') = REPLACE(ros.[NETIQWORKERID], ' ', '')\n",
    "\t  INNER JOIN [UXID].[REF].[Departments] AS dept WITH(NOLOCK)\n",
    "\t  ON ros.DEPARTMENTID = dept.DEPARTMENTID\n",
    "\t  WHERE (dept.NAME LIKE '%Video%')\n",
    "\t  AND (shr.StdDate BETWEEN '{gvp.decide_fm_beginning(shrink_fm).strftime(\"%m/%d/%Y\")}' AND '{gvp.decide_fm_end(current_fm).strftime(\"%m/%d/%Y\")}') \n",
    "\t  AND ((shr.ShrinkType LIKE '%Out of Center%') \n",
    "\t  OR (shr.ShrinkType Like '%Scheduled%'))\n",
    "\t  GROUP BY shr.StdDate, shr.EmpID, shr.ShrinkType) as Shrink_Table\n",
    "PIVOT(\n",
    "\tSUM([Shrink (sec)])\n",
    "\tFOR [ShrinkType] IN ([Out of Center - Planned], [Out of Center - Unplanned], [Scheduled Hours])\n",
    "\t) AS piv\n",
    "ORDER BY [StdDate] DESC, EmpID ASC;\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_str = (\"Driver={SQL Server};\"\n",
    "            \"Server=;\" # Network Server Address\n",
    "            \"Database=Aspect;\"\n",
    "            \"Trusted_Connection=yes;\"\n",
    "            \"MultiSubnetFailover=True;\"\n",
    "            \"ApplicationIntent=ReadOnly;\")\n",
    "conn = pyodbc.connect(conn_str, readonly=True)\n",
    "print('Connected to Server')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roster_path = r\"\" # Network Share drive\n",
    "\n",
    "# retreiving roster from traffic server\n",
    "print('Retrieving Roster')\n",
    "roster_df = pd.read_csv(roster_path)\n",
    "print('Roster Dataframe Created')\n",
    "print('-'*25)\n",
    "\n",
    "# correcting roster dataframe\n",
    "roster_df = roster_df.loc[roster_df['TERMINATEDDATE'].isna()]\n",
    "roster_df['NETIQWORKERID'] = roster_df['NETIQWORKERID'].astype(int).astype(str)\n",
    "roster_df['HIREDATE'] = pd.to_datetime(roster_df['HIREDATE']).dt.date\n",
    "# roster_df['WP Start Date'] = pd.to_datetime(roster_df['WP Start Date']).dt.date\n",
    "print('Roster corrected')\n",
    "\n",
    "# splitting the location into centers as well as correcting for Gran Vista\n",
    "for index, row in roster_df.iterrows():\n",
    "    call_center = row['MGMTAREANAME']\n",
    "    location = row['WorkLocation']\n",
    "    city = ' '.join(location.split(' ')[1:])\n",
    "    state = location.split(' ')[0]\n",
    "\n",
    "    updated_location = f'{city} {state}'\n",
    "    if 'Gran Vista' in call_center:\n",
    "        updated_location = f'{updated_location} (Gran Vista)'\n",
    "    roster_df.loc[index, 'MGMTAREANAME'] = updated_location  # type: ignore\n",
    "\n",
    "rename_dict = {'BossName': 'Supervisor',\n",
    "               'BossBossName': 'Manager',\n",
    "               'EmpName': 'Agent',\n",
    "               'EmpTitle': 'Title',\n",
    "               'NETIQWORKERID': 'PSID',\n",
    "               'STATUSID': 'Status',\n",
    "               'MGMTAREANAME': 'Call Center',\n",
    "               'HIREDATE': 'Hire Date'}\n",
    "roster_df = roster_df.rename(columns=rename_dict)\n",
    "print('Corrected roster column names.')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in the shrink dataframe from traffic server and correcting datatypes\n",
    "print('Retrieving shrink data')\n",
    "shrink_df = pd.read_sql(shrink_query, conn)\n",
    "print('Shrink Data loaded')\n",
    "print('-'*25)\n",
    "shrink_df['Date'] = pd.to_datetime(shrink_df['Date']).dt.date\n",
    "shrink_df['EmpID'] = shrink_df['EmpID'].astype(str)\n",
    "\n",
    "# calculating the final shrink for fiscal months inside of the lookback period\n",
    "lookback_dates = [gvp.decide_fm_end(\n",
    "    current_fm - relativedelta(months=value)) for value in range(months_to_pull)]\n",
    "\n",
    "final_shrink_df = pd.DataFrame()\n",
    "\n",
    "for end_date in lookback_dates:\n",
    "    if end_date.month == current_fm.month:\n",
    "        end_date = yesterday\n",
    "\n",
    "    start_date = gvp.decide_fm_beginning(end_date + relativedelta(months=-2))\n",
    "    fiscal_month = gvp.decide_fm(end_date)\n",
    "\n",
    "    print(\n",
    "        f'Shrink Fiscal Month: {fiscal_month} \\nStart Date: {start_date} \\nEnd Date: {end_date}')\n",
    "    print('-'*25)\n",
    "\n",
    "    df = shrink_df.loc[shrink_df['Date'].between(start_date, end_date)]\n",
    "\n",
    "    df['FiscalMonth'] = fiscal_month\n",
    "\n",
    "    df = df.groupby(['FiscalMonth', 'EmpID']).agg({\n",
    "        'Unplanned OOO': 'sum',\n",
    "        'Scheduled': 'sum'\n",
    "    }).reset_index()\n",
    "\n",
    "    df['Attendance'] = 1 - (df['Unplanned OOO'] / df['Scheduled'])\n",
    "    df = df.drop(columns=['Unplanned OOO', 'Scheduled'])\n",
    "\n",
    "    final_shrink_df = pd.concat(\n",
    "        [final_shrink_df, df], axis=0, ignore_index=True)\n",
    "print('Shrink has been calculated')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in the shrink dataframe from traffic server and correcting datatypes\n",
    "print('Retrieving hours data')\n",
    "hours_df = pd.read_sql(hours_query, conn)\n",
    "print('hours Data loaded')\n",
    "print('-'*25)\n",
    "hours_df['Date'] = pd.to_datetime(hours_df['Date']).dt.date\n",
    "hours_df['EmpID'] = hours_df['EmpID'].astype(str)\n",
    "hours_df = hours_df.fillna(0)\n",
    "hours_df['Hours Worked'] = (hours_df['Scheduled Hours'] - (hours_df['Out of Center - Planned'] + hours_df['Out of Center - Unplanned'])) / 3600\n",
    "hours_df['Hours Worked'] = hours_df['Hours Worked'].map(lambda x: 0 if x < 0 else x)\n",
    "hours_df['Fiscal Month'] = hours_df['Date'].map(gvp.decide_fm)\n",
    "\n",
    "hours_fm_df = hours_df.groupby(['Fiscal Month', 'EmpID']).agg({\n",
    "    'Hours Worked': 'sum'\n",
    "}).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in the mstr data excel sheet and merging with attendance data\n",
    "scorecard_df = pd.read_excel(scorecard_data, engine='openpyxl')\n",
    "scorecard_df['Agent - HR Number'] = scorecard_df['Agent - HR Number'].astype(\n",
    "    str)\n",
    "scorecard_df['Fiscal Mth'] = pd.to_datetime(\n",
    "    scorecard_df['Fiscal Mth'], format='%B %Y').dt.date\n",
    "scorecard_df = scorecard_df.merge(final_shrink_df, how='left', left_on=[\n",
    "                                  'Fiscal Mth', 'Agent - HR Number'], right_on=['FiscalMonth', 'EmpID']).drop(columns=['FiscalMonth', 'EmpID'])\n",
    "print('Scorecard data merged with shrink data')\n",
    "\n",
    "# renaming columns\n",
    "rename_dict = {'Agent - HR Number': 'PSID',\n",
    "               'Calls Handled': 'Calls',\n",
    "               'Transfer Rate': 'Transfer Prevention',\n",
    "               'FCR': 'FCR %',\n",
    "               'Truck Roll Prevention': 'TRP %',\n",
    "               'Attendance %': 'Attendance'}\n",
    "scorecard_df = scorecard_df.rename(columns=rename_dict)\n",
    "\n",
    "# calculating the transfer prefention, then adding in the roster data to the scorecard data\n",
    "scorecard_df['Transfer Prevention'] = 1 - scorecard_df['Transfer Prevention']\n",
    "scorecard_df = roster_df.loc[(roster_df['Title'].str.startswith('Rep ')) & ((roster_df['Title'].str.contains('Video')) | (roster_df['Title'].str.contains('Disability'))), [\n",
    "    'Call Center', 'Manager', 'Supervisor', 'Agent', 'PID', 'PSID', 'Title', 'Hire Date']].merge(scorecard_df, how='inner', on='PSID')\n",
    "print('Scorecard merged with roster')\n",
    "\n",
    "scorecard_df = scorecard_df.merge(hours_fm_df, how='left', left_on=['PSID', 'Fiscal Mth'], right_on=['EmpID','Fiscal Month']).drop(columns=['EmpID','Fiscal Month'])\n",
    "print('Scorecard merged with hours worked')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in the thresholds used to calculate agent's overall performance and correcting it\n",
    "threshold_df = pd.read_excel(threshold_path, engine='openpyxl')\n",
    "threshold_df.loc[threshold_df['Metric'] != 'AHT', 'Red'] = threshold_df.loc[threshold_df['Metric']\n",
    "                                                                            != 'AHT', 'Red'].map(lambda x: ''.join(x[2:-1]))\n",
    "threshold_df.loc[threshold_df['Metric'] == 'AHT',\n",
    "                 'Red'] = threshold_df.loc[threshold_df['Metric'] == 'AHT', 'Red'].map(lambda x: ''.join(x[2:]))\n",
    "threshold_df['Red'] = threshold_df['Red'].astype(float)\n",
    "threshold_df.loc[threshold_df['Metric'] != 'AHT',\n",
    "                 'Red'] = threshold_df.loc[threshold_df['Metric'] != 'AHT', 'Red'] / 100\n",
    "date_list = ['StartDate', 'StopDate']\n",
    "for date_column in date_list:\n",
    "    threshold_df[date_column] = pd.to_datetime(\n",
    "        threshold_df[date_column]).dt.date\n",
    "print('Thresholds loaded')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looping through each unique fiscal month in the data, as well as each title, and each metric in order to calculate scorecard data\n",
    "title_list = scorecard_df['Title'].unique().tolist()\n",
    "metric_list = threshold_df['Metric'].unique().tolist()\n",
    "fiscal_mths = scorecard_df['Fiscal Mth'].unique().tolist()\n",
    "\n",
    "color_dict = {'Blue': 3,\n",
    "              'Green': 3,\n",
    "              'Yellow': 2,\n",
    "              'Red': 1}\n",
    "\n",
    "for month in fiscal_mths:\n",
    "    for title in title_list:\n",
    "        for metric in metric_list:\n",
    "            green = threshold_df.loc[(threshold_df['JobCodeDesc'] == title) & (threshold_df['Metric'] == metric) & (\n",
    "                threshold_df['StartDate'] <= month) & (threshold_df['StopDate'] >= month), 'Green'].values[0]  # type: ignore\n",
    "            yellow = threshold_df.loc[(threshold_df['JobCodeDesc'] == title) & (threshold_df['Metric'] == metric) & (\n",
    "                threshold_df['StartDate'] <= month) & (threshold_df['StopDate'] >= month), 'Yellow'].values[0]  # type: ignore\n",
    "            blue = threshold_df.loc[(threshold_df['JobCodeDesc'] == title) & (threshold_df['Metric'] == metric) & (\n",
    "                threshold_df['StartDate'] <= month) & (threshold_df['StopDate'] >= month), 'Level Up!'].values[0]  # type: ignore\n",
    "            weight = threshold_df.loc[(threshold_df['JobCodeDesc'] == title) & (threshold_df['Metric'] == metric) & (\n",
    "                threshold_df['StartDate'] <= month) & (threshold_df['StopDate'] >= month), 'Weighting'].values[0]  # type: ignore\n",
    "\n",
    "            if metric == 'AHT':\n",
    "                if blue != blue:  # checks to see if null\n",
    "                    scorecard_df.loc[(scorecard_df['Title'] == title) & (scorecard_df[metric] <= green) & (\n",
    "                        scorecard_df['Fiscal Mth'] == month), f'{metric} color'] = 'Green'\n",
    "                else:\n",
    "                    scorecard_df.loc[(scorecard_df['Title'] == title) & (scorecard_df[metric] <= blue) & (\n",
    "                        scorecard_df['Fiscal Mth'] == month), f'{metric} color'] = 'Blue'\n",
    "                    scorecard_df.loc[(scorecard_df['Title'] == title) & (scorecard_df[metric] <= green) & (\n",
    "                        scorecard_df[metric] > blue) & (scorecard_df['Fiscal Mth'] == month), f'{metric} color'] = 'Green'\n",
    "                scorecard_df.loc[(scorecard_df['Title'] == title) & (scorecard_df[metric] <= yellow) & (\n",
    "                    scorecard_df[metric] > green) & (scorecard_df['Fiscal Mth'] == month), f'{metric} color'] = 'Yellow'\n",
    "                scorecard_df.loc[(scorecard_df['Title'] == title) & (scorecard_df[metric] > yellow) & (\n",
    "                    scorecard_df['Fiscal Mth'] == month), f'{metric} color'] = 'Red'\n",
    "\n",
    "            else:\n",
    "                if blue != blue:  # checks to see if null\n",
    "                    scorecard_df.loc[(scorecard_df['Title'] == title) & (scorecard_df[metric] >= green) & (\n",
    "                        scorecard_df['Fiscal Mth'] == month), f'{metric} color'] = 'Green'\n",
    "                else:\n",
    "                    scorecard_df.loc[(scorecard_df['Title'] == title) & (scorecard_df[metric] >= blue) & (\n",
    "                        scorecard_df['Fiscal Mth'] == month), f'{metric} color'] = 'Blue'\n",
    "                    scorecard_df.loc[(scorecard_df['Title'] == title) & (scorecard_df[metric] >= green) & (\n",
    "                        scorecard_df[metric] < blue) & (scorecard_df['Fiscal Mth'] == month), f'{metric} color'] = 'Green'\n",
    "                scorecard_df.loc[(scorecard_df['Title'] == title) & (scorecard_df[metric] >= yellow) & (\n",
    "                    scorecard_df[metric] < green) & (scorecard_df['Fiscal Mth'] == month), f'{metric} color'] = 'Yellow'\n",
    "                scorecard_df.loc[(scorecard_df['Title'] == title) & (scorecard_df[metric] < yellow) & (\n",
    "                    scorecard_df['Fiscal Mth'] == month), f'{metric} color'] = 'Red'\n",
    "\n",
    "            for key, value in color_dict.items():\n",
    "                scorecard_df.loc[scorecard_df[f'{metric} color']\n",
    "                                 == key, f'{metric} score'] = value * weight\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorecard_df = scorecard_df.replace([np.inf, -np.inf], 0)\n",
    "scores_columns = [\n",
    "    value for value in scorecard_df.columns if value.endswith('score')]  # type: ignore\n",
    "scorecard_df['Weighted score'] = scorecard_df.loc[:,\n",
    "                                                  scores_columns].sum(axis=1)\n",
    "\n",
    "# filling score columns with null if data is not complete\n",
    "for column in scores_columns:\n",
    "    scorecard_df.loc[scorecard_df[column].isna(), 'Weighted score'] = np.nan\n",
    "\n",
    "# calculating overall color based on rounded numbers with .5 rounding up\n",
    "scorecard_df['Color score'] = scorecard_df['Weighted score'].loc[scorecard_df['Weighted score'].notna()].map(\n",
    "    lambda x: round_half_up(x, decimals=0))\n",
    "scorecard_df.loc[scorecard_df['Color score'] == 3, 'Overall Color'] = 'Green'\n",
    "scorecard_df.loc[scorecard_df['Color score'] == 2, 'Overall Color'] = 'Yellow'\n",
    "scorecard_df.loc[scorecard_df['Color score'] == 1, 'Overall Color'] = 'Red'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_up_list = threshold_df.loc[threshold_df['Level Up Metric'] == 'Yes', 'Metric'].unique().tolist() # list of metrics that are used for level up\n",
    "level_up_list = [f'{value} color' for value in level_up_list] # adding color to end of list to match dataframe column names\n",
    "\n",
    "level_up_df = scorecard_df # creating a copy of dataframe to pare down to those who qualify for level up\n",
    "for metric in level_up_list: # looping through metrics in order to \n",
    "    level_up_df = level_up_df.loc[level_up_df[metric] == 'Blue']\n",
    "level_up_df = level_up_df.loc[(level_up_df['Calls'] >= 200) & (level_up_df['Hours Worked'] >= 80)]\n",
    "\n",
    "level_up_df['Level Up'] = True\n",
    "scorecard_df = scorecard_df.merge(level_up_df.loc[:,['PSID', 'Fiscal Mth', 'Level Up']], how='left', on=['PSID', 'Fiscal Mth'])\n",
    "scorecard_df.loc[scorecard_df['Level Up'] == True, 'Overall Color'] = 'Blue'\n",
    "scorecard_df = scorecard_df.drop(columns='Level Up')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pulling in the prior scorecard data, first the new data, and if there is still data missing, then the old scorecard data\n",
    "prior_scorecard_df = pd.read_excel(new_scorecard_path)\n",
    "\n",
    "prior_scorecard_df['Fiscal Mth'] = pd.to_datetime(\n",
    "    prior_scorecard_df['Fiscal Mth']).dt.date\n",
    "prior_scorecard_df['PSID'] = prior_scorecard_df['PSID'].astype(str)\n",
    "\n",
    "max_month = scorecard_df['Fiscal Mth'].min() - relativedelta(months=1)\n",
    "\n",
    "cooking_df = scorecard_df.loc[:, ['PSID', 'Fiscal Mth', 'Overall Color', 'Weighted score']].rename(\n",
    "    columns={'Weighted score': 'Overall Score'})\n",
    "cooked_df = prior_scorecard_df.loc[prior_scorecard_df['Fiscal Mth'] <= max_month]\n",
    "update_prior = [cooking_df, cooked_df]\n",
    "\n",
    "# update the new scorecard data file with the newly calculated values\n",
    "pd.concat(update_prior, axis=0, ignore_index=True).sort_values(\n",
    "    by=['Fiscal Mth', 'PSID']).to_excel(new_scorecard_path, index=False)\n",
    "\n",
    "# dropping the score columns since they are unnecceary after having color\n",
    "scores_columns = [\n",
    "    value for value in scorecard_df.columns if value.endswith('score')]  # type: ignore\n",
    "scorecard_df = scorecard_df.drop(columns=scores_columns)\n",
    "\n",
    "prior_scorecard_df = prior_scorecard_df.drop(\n",
    "    columns='Overall Score').rename(columns={'Overall Color': 'Overall'})\n",
    "\n",
    "prior_scorecard_df = prior_scorecard_df.loc[prior_scorecard_df['Fiscal Mth'].between(\n",
    "    lookback_month, max_month)]\n",
    "\n",
    "if prior_scorecard_df['Fiscal Mth'].min() > lookback_month:\n",
    "    old_scorecard_df = pd.read_excel(old_scorecard_path)\n",
    "    old_scorecard_df['Fiscal Mth'] = pd.to_datetime(\n",
    "        old_scorecard_df['Fiscal Mth']).dt.date\n",
    "    old_scorecard_df['PSID'] = old_scorecard_df['PSID'].astype(str)\n",
    "    prior_scorecard_df = pd.concat(\n",
    "        [prior_scorecard_df, old_scorecard_df], axis=0, ignore_index=True)\n",
    "    prior_scorecard_df = prior_scorecard_df.loc[prior_scorecard_df['Fiscal Mth'].between(\n",
    "        lookback_month, max_month)]\n",
    "\n",
    "flux_df = scorecard_df.rename(columns={'Overall Color': 'Overall'}).loc[scorecard_df['Fiscal Mth'] != current_fm, [\n",
    "    'PSID', 'Fiscal Mth', 'Overall']]\n",
    "prior_scorecard_df = pd.concat(\n",
    "    [prior_scorecard_df, flux_df], axis=0, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding in the level up qualified column\n",
    "prior_scorecard_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_up_month = current_fm - relativedelta(months=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nine_mo_df = prior_scorecard_df.loc[prior_scorecard_df['Overall'] == 'Blue']\\\n",
    "                    .groupby('PSID').agg({\n",
    "                        'Fiscal Mth':'count'\n",
    "                    }).reset_index()\n",
    "nine_mo_df = nine_mo_df.loc[nine_mo_df['Fiscal Mth'] >= 6]\n",
    "nine_mo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_mo_df = prior_scorecard_df.loc[(prior_scorecard_df['Fiscal Mth'] >= level_up_month) & (prior_scorecard_df['Overall'] == 'Blue')]\\\n",
    "    .groupby('PSID').agg({\n",
    "        'Fiscal Mth': 'count'\n",
    "    }).reset_index()\n",
    "four_mo_df = four_mo_df.loc[four_mo_df['Fiscal Mth'] >= 4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_up_list = pd.concat([four_mo_df, nine_mo_df], axis=0, ignore_index=True)['PSID'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_list = prior_scorecard_df['Fiscal Mth'].unique().tolist()\n",
    "month_list.sort(reverse=True)\n",
    "month_list = [value.strftime('%b %y') for value in month_list]\n",
    "\n",
    "prior_scorecard_df['Fiscal Mth'] = pd.to_datetime(\n",
    "    prior_scorecard_df['Fiscal Mth']).dt.strftime('%b %y')\n",
    "\n",
    "prior_scorecard_df = prior_scorecard_df.pivot(\n",
    "    index='PSID', columns='Fiscal Mth', values='Overall').reindex(columns=month_list).reset_index()\n",
    "\n",
    "current_scorecard_df = scorecard_df.loc[scorecard_df['Fiscal Mth'] == current_fm]\n",
    "\n",
    "new_column_order = ['Call Center',\n",
    "                    'Manager',\n",
    "                    'Supervisor',\n",
    "                    'Agent',\n",
    "                    'PID',\n",
    "                    'PSID',\n",
    "                    'Title',\n",
    "                    'Hire Date',\n",
    "                    'Calls',\n",
    "                    'Hours Worked',\n",
    "                    'Overall Color',\n",
    "                    'Attendance',\n",
    "                    'Attendance color',\n",
    "                    'FCR %',\n",
    "                    'FCR % color',\n",
    "                    'SAM %',\n",
    "                    'SAM % color',\n",
    "                    'Transfer Prevention',\n",
    "                    'Transfer Prevention color',\n",
    "                    'AHT',\n",
    "                    'AHT color',\n",
    "                    'TRP %',\n",
    "                    'TRP % color']\n",
    "\n",
    "current_scorecard_df = current_scorecard_df.reindex(columns=new_column_order).rename(\n",
    "    columns={'Overall Color': 'Overall', 'Transfer Prevention': 'Xfer Prev'}).sort_values(by=['Call Center', 'Manager', 'Supervisor', 'Agent'])\n",
    "\n",
    "current_scorecard_df['Agent'] = current_scorecard_df['Agent'].map(\n",
    "    lambda x: x.title())\n",
    "current_scorecard_df['Supervisor'] = current_scorecard_df['Supervisor'].map(\n",
    "    lambda x: x.title())\n",
    "current_scorecard_df['Manager'] = current_scorecard_df['Manager'].map(\n",
    "    lambda x: x.title())\n",
    "\n",
    "\n",
    "final_scorecard_df = current_scorecard_df.merge(\n",
    "    prior_scorecard_df, how='left', on='PSID')\n",
    "\n",
    "output_file = 'final_scorecard_data.xlsx'\n",
    "output_path = os.path.join(data_folder, output_file)\n",
    "final_scorecard_df.to_excel(\n",
    "    output_path, index=False, sheet_name='Scorecard Data')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_scorecard_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Opening Excel\")\n",
    "xlapp = win32com.client.Dispatch('Excel.Application')\n",
    "xlapp.Visible = True\n",
    "xlapp.DisplayAlerts = False\n",
    "wb = xlapp.Workbooks.Open(template_path)\n",
    "print('Excel has been opened')\n",
    "\n",
    "# refreshing all queries\n",
    "wb.RefreshAll()\n",
    "xlapp.CalculateUntilAsyncQueriesDone()\n",
    "wb.Worksheets('Summary Pivot').PivotTables(\n",
    "    \"PivotTable1\").PivotCache().Refresh()\n",
    "print('Excel Data has been refreshed.')\n",
    "\n",
    "# deleting connections for output file\n",
    "for conn in wb.Queries:\n",
    "    conn.Delete()\n",
    "print('Connections have been removed.')\n",
    "\n",
    "ws = wb.Worksheets('Scorecard Outliers')\n",
    "ws.Range('B9').Value = yesterday.strftime('%m/%d/%Y')\n",
    "print('Updated the Update Date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws.Range('AG:XFD').EntireColumn.Hidden = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws.ListObjects(\"Scorecard_Data\").ShowAutoFilterDropDown = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving file in the determined folder and quitting excel\n",
    "wb.SaveAs(save_path)\n",
    "print(f'Workbook has been saved here: {save_path}')\n",
    "xlapp.DisplayAlerts = True\n",
    "wb.Close()\n",
    "xlapp.Quit()\n",
    "print('Excel has been closed.')\n",
    "\n",
    "# outputting to the website\n",
    "# copy(save_path, server_path)\n",
    "print(f'Report has been saved to {server_path}')\n",
    "\n",
    "# declaring html to build email\n",
    "header = '<td width=951 style=\"width:580.0pt;background:#787878;padding:0in 5.4pt 0in 5.4pt\";height:45.35pt\"><p><span style=\"color:white\"><img src=cid:vid_repair height=51></span></td>'\n",
    "# <p class=MsoNormal><span style='color:black'>Below is a summary after the most recent data refresh.</span></p>\"\n",
    "explainer = \"<p>&nbsp;</p> <p class=MsoNormal><span style='color:black'>You can find the most recent Scorecard Outlier report <a href=''><span style='font-size: 12.0pt'>here</span></a></span><span style='font-size:12.0pt;color:black'>.</span></p>\"\n",
    "conclusion = '<br><p><span style=\"color:black\">If you have any questions, please reach out <a href=\"mailto:\"><span style=\"font-size: 12.0pt\">here</span></a><span style=\"font-size:12.0pt;color:black\">.</span></span></p></br>'\n",
    "footer = f'<tr> <td width=951 valign=top style=\"width:713.4pt;background:#787878;padding: 0in 5.4pt 0in 5.4pt\"> <p style=\"margin-top:6.0pt;margin-right:0in; margin-bottom:6.0pt;margin-left:0in;text-align:center\"><b><span style=\"color:white\"><img border=0 width=168 height=53 src=cid:charter_logo></span></b></p> <p style=\"margin-top:6.0pt;margin-right:0in; margin-bottom:6.0pt;margin-left:0in;text-align:center\"><strong><span style=\"font-size:10.5pt;color:white\">For Internal Use Only</span></strong></p> <p style=\"margin-top:6.0pt;margin-right:0in; margin-bottom:6.0pt;margin-left:0in;text-align:center\"><span style=\"font-size:8.5pt;color:white\">This communication is the property of Charter Communications and is intended for internal use only. Distribution outside of the Company, in whole or part, is not permitted, except with Company permission in the course of your authorized duties. </span></p> <p style=\"margin-bottom:12.0pt;text-align:center\"><b><span style=\"color:white\">Video Reporting &amp; Analytics</span></b></p></td></tr>'\n",
    "body = f'<table border=0 cellspacing=0 cellpadding=0 style=\"border-collapse:collapse\"><tr>{header}</tr><tr>{explainer}</tr><tr align=\"center\"><br></br></tr>{conclusion}<p>&nbsp;</p>{footer}</table>'\n",
    "\n",
    "# generating email\n",
    "print('Launching Outlook')\n",
    "olMailItem = 0x0\n",
    "obj = win32com.client.Dispatch(\"Outlook.Application\")\n",
    "newMail = obj.CreateItem(olMailItem)\n",
    "newMail.Subject = f\"LEADER: Scorecard Outlier - {yesterday.strftime('%m/%d/%y')}\"\n",
    "\n",
    "newMail.To = '' # Network Email Addresses\n",
    "newMail.CC = '' # Network Email Addresses\n",
    "vid_repair_logo = newMail.Attachments.Add(vid_repair)\n",
    "vid_repair_logo.PropertyAccessor.SetProperty(\n",
    "    \"http://schemas.microsoft.com/mapi/proptag/0x3712001F\", \"vid_repair\")\n",
    "charter_logo = newMail.Attachments.Add(logo)\n",
    "charter_logo.PropertyAccessor.SetProperty(\n",
    "    \"http://schemas.microsoft.com/mapi/proptag/0x3712001F\", \"charter_logo\")\n",
    "newMail.HTMLBody = body\n",
    "newMail.Display()\n",
    "# newMail.Send()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
